{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all to generate the entire dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the rectified images to the ./raw_data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import Kitti\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from calibration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.normpath('datasets/')\n",
    "\n",
    "# makes the directory structure\n",
    "if not os.path.exists(path_dataset):\n",
    "    os.mkdir(path_dataset)\n",
    "    os.mkdir('datasets/custom/')\n",
    "    os.mkdir('datasets/custom/training/')\n",
    "    os.mkdir('datasets/custom/training/images/')\n",
    "    os.mkdir('datasets/custom/training/labels/')\n",
    "    os.mkdir('datasets/custom/val/')\n",
    "    os.mkdir('datasets/custom/val/images/')\n",
    "    os.mkdir('datasets/custom/val/labels/')\n",
    "    os.mkdir('datasets/custom/testing/')\n",
    "    os.mkdir('datasets/custom/testing/images/')\n",
    "    os.mkdir('datasets/custom/testing/labels/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip to ./raw_data\\Kitti\\raw\\data_object_image_2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12569945557/12569945557 [23:38<00:00, 8858852.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./raw_data\\Kitti\\raw\\data_object_image_2.zip to ./raw_data\\Kitti\\raw\n",
      "Downloading https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip to ./raw_data\\Kitti\\raw\\data_object_label_2.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5601213/5601213 [00:00<00:00, 10543885.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./raw_data\\Kitti\\raw\\data_object_label_2.zip to ./raw_data\\Kitti\\raw\n"
     ]
    }
   ],
   "source": [
    "# Downloads the KITTI dataset to the folder \n",
    "path_dataset = r\"./raw_data\"\n",
    "kitti_dataset = Kitti(path_dataset, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(labels_dir,img_dir, new_labels_to, new_images_to):\n",
    "    img_shape = (375, 1242)\n",
    "    reverse_labels_dict = {0: 'Pedestrian',\n",
    "                            1: 'Cyclist',\n",
    "                            2: 'Car'}\n",
    "    \n",
    "    labels_dict = { 'Pedestrian': 0,\n",
    "                    'Cyclist': 1,\n",
    "                    'Car': 2}\n",
    "    \n",
    "\n",
    "    for file_ in os.listdir(labels_dir):\n",
    "        tmp_path = os.path.join(labels_dir, file_)\n",
    "        new_file = os.path.join(new_labels_to, file_)\n",
    "        new_lines = []\n",
    "\n",
    "        # Read the data from the labels files\n",
    "        with open(tmp_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                line = line.split(' ')\n",
    "                elements = [line[e] for e in [0, 4, 5, 6, 7]]\n",
    "\n",
    "                # Normalize bbox coordinates\n",
    "                x = (float(elements[1]) + float(elements[3])) / (2 * img_shape[1])\n",
    "                y = (float(elements[2]) + float(elements[4])) / (2 * img_shape[0])\n",
    "                w = (float(elements[3]) - float(elements[1])) / img_shape[1]\n",
    "                h = (float(elements[4]) - float(elements[2])) / img_shape[0]\n",
    "                \n",
    "                elements[1] = x\n",
    "                elements[2] = y\n",
    "                elements[3] = w\n",
    "                elements[4] = h\n",
    "\n",
    "                # Translate type to numbers and convert types of cars and people to standard\n",
    "                type_ = elements[0]\n",
    "                if type_ in ['Pedestrian', 'Person_sitting']:\n",
    "                    elements[0] = labels_dict['Pedestrian']\n",
    "                elif type_ == 'Cyclist':\n",
    "                    elements[0] = labels_dict['Cyclist']\n",
    "                elif type_ in ['Van', 'Truck', 'Car']:\n",
    "                    elements[0] = labels_dict['Car']\n",
    "\n",
    "                # Add the translated elements for the new file                \n",
    "                if elements[0] in labels_dict.values():\n",
    "                    elements = list(map(str, elements))\n",
    "                    tmp_line = ' '.join(elements)\n",
    "                    new_lines.append(tmp_line)\n",
    "\n",
    "        # Write the new translated classes to the new file\n",
    "        with open(new_file, 'w') as f:\n",
    "            for line in new_lines:\n",
    "                f.write(f'{line}\\n')\n",
    "\n",
    "\n",
    "    for file_ in os.listdir(img_dir):\n",
    "        img_path = os.path.join(img_dir,file_)\n",
    "        copy_path = os.path.join(new_images_to,file_)\n",
    "\n",
    "        shutil.copyfile(img_path, copy_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset2(labels_dir,img_dir, new_labels_to, new_images_to, addon_name):\n",
    "    reverse_labels_dict = {0: 'Pedestrian',\n",
    "                            1: 'Cyclist',\n",
    "                            2: 'Car'}\n",
    "    labels_dict = { 'Pedestrian': 0,\n",
    "                    'Cyclist': 1,\n",
    "                    'Car': 2}    \n",
    "\n",
    "\n",
    "\n",
    "    df_temp = pd.read_csv(labels_dir, sep=' ', header=None)\n",
    "    df_labels = pd.DataFrame(data={\n",
    "    'frame': df_temp[0],\n",
    "    'id': df_temp[1],\n",
    "    'label': df_temp[2],\n",
    "    'truncated': df_temp[3],\n",
    "    'occluded': df_temp[4],\n",
    "    'alpha': df_temp[5],\n",
    "    'bbox': list(df_temp[list(range(6, 10))].values),\n",
    "    'dimensions': df_temp[list(range(10, 13))].values.tolist(),\n",
    "    'location': df_temp[list(range(13, 16))].values.tolist(),\n",
    "    'rotation_y': df_temp[16],\n",
    "    # 'score': df_temp[16],\n",
    "    })\n",
    "\n",
    "\n",
    "    df_labels['label'] = df_labels['label'].replace(labels_dict)\n",
    "\n",
    "\n",
    "\n",
    "    for idx, img_file in enumerate(os.listdir(img_dir)):\n",
    "    \n",
    "        path_to_file = os.path.join(img_dir, img_file)\n",
    "        # print(path_to_file)\n",
    "        img_save_path = os.path.join(new_images_to, addon_name + img_file)\n",
    "        label_save_path = os.path.join(new_labels_to, addon_name + img_file.split('.')[0] + '.txt')\n",
    "\n",
    "        # Block to rectify and save image into custom dataset\n",
    "        img_bgr = cv2.imread(path_to_file)\n",
    "        height, width = img_bgr.shape[:2]\n",
    "        # img_rectified = rectify_frame(img_bgr, left_cam_params)\n",
    "        cv2.imwrite(img_save_path, img_bgr)\n",
    "\n",
    "        # Block to save image labels into custom dataset\n",
    "        img_labels = df_labels[df_labels['frame'] == idx].copy()\n",
    "        img_labels = img_labels[['label', 'bbox']]\n",
    "        x_col, y_col, w_col, h_col = [], [], [], []\n",
    "        for i, (x, y, w, h) in enumerate(img_labels['bbox']):\n",
    "            x_norm = ((w + x) / 2) / width\n",
    "            w_norm = (w - x) / width\n",
    "            y_norm = ((h + y) / 2) / height\n",
    "            h_norm = (h - y) / height\n",
    "\n",
    "            x_col.append(x_norm)\n",
    "            y_col.append(y_norm)\n",
    "            w_col.append(w_norm)\n",
    "            h_col.append(h_norm)\n",
    "            # img_labels['bbox'].iloc[i] = '{} {} {} {}'.format(x_norm, y_norm, w_norm, h_norm)\n",
    "        \n",
    "        img_labels = img_labels.assign(x_norm = x_col,\n",
    "                                                    y_norm = y_col,\n",
    "                                                    w_norm = w_col,\n",
    "                                                    h_norm = h_col) \n",
    "        img_labels.drop('bbox', axis=1, inplace=True)\n",
    "        img_labels.to_csv(label_save_path, sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_test(labels_dir,img_dir, new_labels_to, new_images_to, addon_name):\n",
    "    reverse_labels_dict = {0: 'Pedestrian',\n",
    "                            1: 'Cyclist',\n",
    "                            2: 'Car'}\n",
    "    labels_dict = { 'Pedestrian': 0,\n",
    "                    'Cyclist': 1,\n",
    "                    'Car': 2}    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for idx, img_file in enumerate(os.listdir(img_dir)):\n",
    "    \n",
    "        path_to_file = os.path.join(img_dir, img_file)\n",
    "        # print(path_to_file)\n",
    "        img_save_path = os.path.join(new_images_to, addon_name + img_file)\n",
    "        label_save_path = os.path.join(new_labels_to, addon_name + img_file.split('.')[0] + '.txt')\n",
    "\n",
    "        # Block to rectify and save image into custom dataset\n",
    "        img_bgr = cv2.imread(path_to_file)\n",
    "        height, width = img_bgr.shape[:2]\n",
    "        # img_rectified = rectify_frame(img_bgr, left_cam_params)\n",
    "        cv2.imwrite(img_save_path, img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the different datasets\n",
    "root_dir = os.getcwd()\n",
    "\n",
    "\n",
    "# Training set \n",
    "training_labels_dir = os.path.join(root_dir,r\"raw_data\\Kitti\\raw\\training\\label_2\")\n",
    "training_new_labels_to = os.path.join(root_dir, r\"datasets\\custom\\training\\labels\")\n",
    "training_img_dir = os.path.join(root_dir, r\"raw_data\\Kitti\\raw\\training\\image_2\")\n",
    "training_new_images_to = os.path.join(root_dir, r\"datasets\\custom\\training\\images\")\n",
    "\n",
    "if not os.listdir(training_new_images_to):\n",
    "    if not os.listdir(training_new_labels_to):\n",
    "        create_dataset(training_labels_dir,training_img_dir, training_new_labels_to, training_new_images_to)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set \n",
    "val_labels_dir1 = os.path.join(root_dir,r\"raw_data\\rectified\\seq_01\\labels.txt\")\n",
    "val_labels_dir2 = os.path.join(root_dir,r\"raw_data\\rectified\\seq_02\\labels.txt\")\n",
    "val_new_labels_to = os.path.join(root_dir, r\"datasets\\custom\\val\\labels\")\n",
    "val_img_dir1 = os.path.join(root_dir, r\"raw_data\\rectified\\seq_01\\image_02\\data\")\n",
    "val_img_dir2 = os.path.join(root_dir, r\"raw_data\\rectified\\seq_02\\image_02\\data\")\n",
    "val_new_images_to = os.path.join(root_dir, r\"datasets\\custom\\val\\images\")\n",
    "\n",
    "if not os.listdir(val_new_images_to):\n",
    "    if not os.listdir(val_new_labels_to):\n",
    "        create_dataset2(val_labels_dir1,val_img_dir1, val_new_labels_to, val_new_images_to,\"seq01_\")\n",
    "        create_dataset2(val_labels_dir2,val_img_dir2, val_new_labels_to, val_new_images_to,\"seq02_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "test_labels_dir = os.path.join(root_dir,r\"raw_data\\rectified\\seq_03\\labels.txt\")\n",
    "test_new_labels_to = os.path.join(root_dir, r\"datasets\\custom\\testing\\labels\")\n",
    "test_img_dir = os.path.join(root_dir, r\"raw_data\\rectified\\seq_03\\image_02\\data\")\n",
    "test_new_images_to = os.path.join(root_dir, r\"datasets\\custom\\testing\\images\")\n",
    "\n",
    "if not os.listdir(test_new_images_to):\n",
    "    if not os.listdir(test_new_labels_to):\n",
    "        create_dataset_test(test_labels_dir,test_img_dir, test_new_labels_to, test_new_images_to,\"seq03_\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Perception",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
